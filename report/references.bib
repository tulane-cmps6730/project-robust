@book{aho1972theory,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@inproceedings{NEURIPS2021_1415fe9f,
 author = {Iwasawa, Yusuke and Matsuo, Yutaka},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {2427--2440},
 publisher = {Curran Associates, Inc.},
 title = {Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/1415fe9fea0fa1e45dddcff5682239a0-Paper.pdf},
 volume = {34},
 year = {2021}
}

@inproceedings{
wang2021tent,
title={Tent: Fully Test-Time Adaptation by Entropy Minimization},
author={Dequan Wang and Evan Shelhamer and Shaoteng Liu and Bruno Olshausen and Trevor Darrell},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=uXl3bZLkr3c}
}
@inproceedings{samadh2023align,
  title={Align your prompts: Test-time prompting with distribution alignment for zero-shot generalization},
  author={Samadh, Jameel Hassan Abdul and Gani, Hanan and Hussein, Noor Hazim and Khattak, Muhammad Uzair and Naseer, Muzammal and Khan, Fahad and Khan, Salman},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{zheng2022prompt,
  title={Prompt vision transformer for domain generalization},
  author={Zheng, Zangwei and Yue, Xiangyu and Wang, Kai and You, Yang},
  journal={arXiv preprint arXiv:2208.08914},
  year={2022}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@article{flamary2021pot,
  author  = {R{\'e}mi Flamary and Nicolas Courty and Alexandre Gramfort and Mokhtar Z. Alaya and Aur{\'e}lie Boisbunon and Stanislas Chambon and Laetitia Chapel and Adrien Corenflos and Kilian Fatras and Nemo Fournier and L{\'e}o Gautheron and Nathalie T.H. Gayraud and Hicham Janati and Alain Rakotomamonjy and Ievgen Redko and Antoine Rolet and Antony Schutz and Vivien Seguy and Danica J. Sutherland and Romain Tavenard and Alexander Tong and Titouan Vayer},
  title   = {POT: Python Optimal Transport},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {78},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-451.html}
}

@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric and others},
  volume={338},
  year={2009},
  publisher={Springer}
}

@inproceedings{kantorovich1942translocation,
  title={On the translocation of masses},
  author={Kantorovich, Leonid V},
  booktitle={Dokl. Akad. Nauk. USSR (NS)},
  volume={37},
  pages={199--201},
  year={1942}
}

@article{peyre2019computational,
  title={Computational optimal transport: With applications to data science},
  author={Peyr{\'e}, Gabriel and Cuturi, Marco and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={5-6},
  pages={355--607},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@article{courty2016optimal,
  title={Optimal transport for domain adaptation},
  author={Courty, Nicolas and Flamary, R{\'e}mi and Tuia, Devis and Rakotomamonjy, Alain},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={9},
  pages={1853--1865},
  year={2016},
  publisher={IEEE}
}

@article{alvarez2020geometric,
  title={Geometric dataset distances via optimal transport},
  author={Alvarez-Melis, David and Fusi, Nicolo},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21428--21439},
  year={2020}
}

@article{cuturi2013sinkhorn,
  title={Sinkhorn distances: Lightspeed computation of optimal transport},
  author={Cuturi, Marco},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{mehra2023analysis,
  title={Analysis of task transferability in large pre-trained classifiers},
  author={Mehra, Akshay and Zhang, Yunbei and Hamm, Jihun},
  journal={arXiv preprint arXiv:2307.00823},
  year={2023}
}

@inproceedings{li2017deeper,
  title={Deeper, broader and artier domain generalization},
  author={Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5542--5550},
  year={2017}
}

@inproceedings{fang2013unbiased,
  title={Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias},
  author={Fang, Chen and Xu, Ye and Rockmore, Daniel N},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1657--1664},
  year={2013}
}

@InProceedings{Venkateswara_2017_CVPR,
author = {Venkateswara, Hemanth and Eusebio, Jose and Chakraborty, Shayok and Panchanathan, Sethuraman},
title = {Deep Hashing Network for Unsupervised Domain Adaptation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@article{gulrajani2020search,
  title={In search of lost domain generalization},
  author={Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:2007.01434},
  year={2020}
}

@article{hendrycks2019benchmarking,
  title={Benchmarking neural network robustness to common corruptions and perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1903.12261},
  year={2019}
}

@inproceedings{recht2019imagenet,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International conference on machine learning},
  pages={5389--5400},
  year={2019},
  organization={PMLR}
}

@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and others},
  booktitle={International conference on machine learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@article{ma2024swapprompt,
  title={SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models},
  author={Ma, Xiaosong and Zhang, Jie and Guo, Song and Xu, Wenchao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@misc{
gao2023visual,
title={Visual Prompt Tuning For Test-time Domain Adaptation},
author={Yunhe Gao and Xingjian Shi and Yi Zhu and Hao Wang and Zhiqiang Tang and Xiong Zhou and Mu Li and Dimitris N. Metaxas},
year={2023},
url={https://openreview.net/forum?id=3HnIBTjlXTS}
}

@article{blanchard2011generalizing,
  title={Generalizing from several related classification tasks to a new unlabeled sample},
  author={Blanchard, Gilles and Lee, Gyemin and Scott, Clayton},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@article{zhou2022domain,
  title={Domain generalization: A survey},
  author={Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={4},
  pages={4396--4415},
  year={2022},
  publisher={IEEE}
}

@inproceedings{
mehra2022do,
title={Do Domain Generalization Methods Generalize Well?},
author={Akshay Mehra and Bhavya Kailkhura and Pin-Yu Chen and Jihun Hamm},
booktitle={NeurIPS ML Safety Workshop},
year={2022},
url={https://openreview.net/forum?id=SRWIQ0Yl53m}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@article{liu2021p,
  title={P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2110.07602},
  year={2021}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={European Conference on Computer Vision},
  pages={709--727},
  year={2022},
  organization={Springer}
}

@misc{sanh2020distilbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{zhang2015character,
  title={Character-level convolutional networks for text classification},
  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{
wang2021tent,
title={Tent: Fully Test-Time Adaptation by Entropy Minimization},
author={Dequan Wang and Evan Shelhamer and Shaoteng Liu and Bruno Olshausen and Trevor Darrell},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=uXl3bZLkr3c}
}
@inproceedings{samadh2023align,
  title={Align your prompts: Test-time prompting with distribution alignment for zero-shot generalization},
  author={Samadh, Jameel Hassan Abdul and Gani, Hanan and Hussein, Noor Hazim and Khattak, Muhammad Uzair and Naseer, Muzammal and Khan, Fahad and Khan, Salman},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{zheng2022prompt,
  title={Prompt vision transformer for domain generalization},
  author={Zheng, Zangwei and Yue, Xiangyu and Wang, Kai and You, Yang},
  journal={arXiv preprint arXiv:2208.08914},
  year={2022}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@article{flamary2021pot,
  author  = {R{\'e}mi Flamary and Nicolas Courty and Alexandre Gramfort and Mokhtar Z. Alaya and Aur{\'e}lie Boisbunon and Stanislas Chambon and Laetitia Chapel and Adrien Corenflos and Kilian Fatras and Nemo Fournier and L{\'e}o Gautheron and Nathalie T.H. Gayraud and Hicham Janati and Alain Rakotomamonjy and Ievgen Redko and Antoine Rolet and Antony Schutz and Vivien Seguy and Danica J. Sutherland and Romain Tavenard and Alexander Tong and Titouan Vayer},
  title   = {POT: Python Optimal Transport},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {78},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-451.html}
}

@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric and others},
  volume={338},
  year={2009},
  publisher={Springer}
}

@inproceedings{kantorovich1942translocation,
  title={On the translocation of masses},
  author={Kantorovich, Leonid V},
  booktitle={Dokl. Akad. Nauk. USSR (NS)},
  volume={37},
  pages={199--201},
  year={1942}
}

@article{peyre2019computational,
  title={Computational optimal transport: With applications to data science},
  author={Peyr{\'e}, Gabriel and Cuturi, Marco and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={5-6},
  pages={355--607},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@article{courty2016optimal,
  title={Optimal transport for domain adaptation},
  author={Courty, Nicolas and Flamary, R{\'e}mi and Tuia, Devis and Rakotomamonjy, Alain},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={9},
  pages={1853--1865},
  year={2016},
  publisher={IEEE}
}

@article{alvarez2020geometric,
  title={Geometric dataset distances via optimal transport},
  author={Alvarez-Melis, David and Fusi, Nicolo},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21428--21439},
  year={2020}
}

@article{cuturi2013sinkhorn,
  title={Sinkhorn distances: Lightspeed computation of optimal transport},
  author={Cuturi, Marco},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{mehra2023analysis,
  title={Analysis of task transferability in large pre-trained classifiers},
  author={Mehra, Akshay and Zhang, Yunbei and Hamm, Jihun},
  journal={arXiv preprint arXiv:2307.00823},
  year={2023}
}

@inproceedings{li2017deeper,
  title={Deeper, broader and artier domain generalization},
  author={Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5542--5550},
  year={2017}
}

@inproceedings{fang2013unbiased,
  title={Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias},
  author={Fang, Chen and Xu, Ye and Rockmore, Daniel N},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1657--1664},
  year={2013}
}

@InProceedings{Venkateswara_2017_CVPR,
author = {Venkateswara, Hemanth and Eusebio, Jose and Chakraborty, Shayok and Panchanathan, Sethuraman},
title = {Deep Hashing Network for Unsupervised Domain Adaptation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@article{gulrajani2020search,
  title={In search of lost domain generalization},
  author={Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:2007.01434},
  year={2020}
}

@article{hendrycks2019benchmarking,
  title={Benchmarking neural network robustness to common corruptions and perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1903.12261},
  year={2019}
}

@inproceedings{recht2019imagenet,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International conference on machine learning},
  pages={5389--5400},
  year={2019},
  organization={PMLR}
}

@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and others},
  booktitle={International conference on machine learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@article{ma2024swapprompt,
  title={SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models},
  author={Ma, Xiaosong and Zhang, Jie and Guo, Song and Xu, Wenchao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@misc{
gao2023visual,
title={Visual Prompt Tuning For Test-time Domain Adaptation},
author={Yunhe Gao and Xingjian Shi and Yi Zhu and Hao Wang and Zhiqiang Tang and Xiong Zhou and Mu Li and Dimitris N. Metaxas},
year={2023},
url={https://openreview.net/forum?id=3HnIBTjlXTS}
}

@article{blanchard2011generalizing,
  title={Generalizing from several related classification tasks to a new unlabeled sample},
  author={Blanchard, Gilles and Lee, Gyemin and Scott, Clayton},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@article{zhou2022domain,
  title={Domain generalization: A survey},
  author={Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={4},
  pages={4396--4415},
  year={2022},
  publisher={IEEE}
}

@inproceedings{
mehra2022do,
title={Do Domain Generalization Methods Generalize Well?},
author={Akshay Mehra and Bhavya Kailkhura and Pin-Yu Chen and Jihun Hamm},
booktitle={NeurIPS ML Safety Workshop},
year={2022},
url={https://openreview.net/forum?id=SRWIQ0Yl53m}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@article{liu2021p,
  title={P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2110.07602},
  year={2021}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={European Conference on Computer Vision},
  pages={709--727},
  year={2022},
  organization={Springer}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{sun2020test,
  title={Test-time training with self-supervision for generalization under distribution shifts},
  author={Sun, Yu and Wang, Xiaolong and Liu, Zhuang and Miller, John and Efros, Alexei and Hardt, Moritz},
  booktitle={International conference on machine learning},
  pages={9229--9248},
  year={2020},
  organization={PMLR}
}

@inproceedings{liang2020we,
  title={Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation},
  author={Liang, Jian and Hu, Dapeng and Feng, Jiashi},
  booktitle={International conference on machine learning},
  pages={6028--6039},
  year={2020},
  organization={PMLR}
}

@article{liang2021source,
  title={Source data-absent unsupervised domain adaptation through hypothesis transfer and labeling transfer},
  author={Liang, Jian and Hu, Dapeng and Wang, Yunbo and He, Ran and Feng, Jiashi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={11},
  pages={8602--8617},
  year={2021},
  publisher={IEEE}
}

@inproceedings{mehra2024fly,
  title={On the Fly Neural Style Smoothing for Risk-Averse Domain Generalization},
  author={Mehra, Akshay and Zhang, Yunbei and Kailkhura, Bhavya and Hamm, Jihun},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3800--3811},
  year={2024}
}

@inproceedings{prabhudesai2023diffusion,
  title={Diffusion-TTA: Test-time Adaptation of Discriminative Models via Generative Feedback},
  author={Prabhudesai, Mihir and Ke, Tsung-Wei and Li, Alexander Cong and Pathak, Deepak and Fragkiadaki, Katerina},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{schneider2020improving,
  title={Improving robustness against common corruptions by covariate shift adaptation},
  author={Schneider, Steffen and Rusak, Evgenia and Eck, Luisa and Bringmann, Oliver and Brendel, Wieland and Bethge, Matthias},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={11539--11551},
  year={2020}
}

@inproceedings{mirza2022norm,
  title={The norm must go on: Dynamic unsupervised domain adaptation by normalization},
  author={Mirza, M Jehanzeb and Micorek, Jakub and Possegger, Horst and Bischof, Horst},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14765--14775},
  year={2022}
}

@inproceedings{mirza2023actmad,
  title={Actmad: Activation matching to align distributions for test-time-training},
  author={Mirza, Muhammad Jehanzeb and Soneira, Pol Jan{\'e} and Lin, Wei and Kozinski, Mateusz and Possegger, Horst and Bischof, Horst},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24152--24161},
  year={2023}
}

@article{mummadi2021test,
  title={Test-time adaptation to distribution shift by confidence maximization and input transformation},
  author={Mummadi, Chaithanya Kumar and Hutmacher, Robin and Rambach, Kilian and Levinkov, Evgeny and Brox, Thomas and Metzen, Jan Hendrik},
  journal={arXiv preprint arXiv:2106.14999},
  year={2021}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Volpi, Riccardo and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@article{mehra2021understanding,
  title={Understanding the limits of unsupervised domain adaptation via data poisoning},
  author={Mehra, Akshay and Kailkhura, Bhavya and Chen, Pin-Yu and Hamm, Jihun},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17347--17359},
  year={2021}
}

@article{liang2023ttasurvey,
  title={A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts},
  author={Liang, Jian and He, Ran and Tan, Tieniu},
  journal={arXiv preprint arXiv:2303.15361},
  year={2023}
}

@article{ge2023domain,
  title={Domain adaptation via prompt learning},
  author={Ge, Chunjiang and Huang, Rui and Xie, Mixue and Lai, Zihang and Song, Shiji and Li, Shuang and Huang, Gao},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}

@article{naseer2021intriguing,
  title={Intriguing properties of vision transformers},
  author={Naseer, Muhammad Muzammal and Ranasinghe, Kanchana and Khan, Salman H and Hayat, Munawar and Shahbaz Khan, Fahad and Yang, Ming-Hsuan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23296--23308},
  year={2021}
}

@article{raghu2021vision,
  title={Do vision transformers see like convolutional neural networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={12116--12128},
  year={2021}
}

@inproceedings{shen2018wasserstein,
  title={Wasserstein distance guided representation learning for domain adaptation},
  author={Shen, Jian and Qu, Yanru and Zhang, Weinan and Yu, Yong},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{NIPS2006_b1b0432c,
 author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {B. Sch\"{o}lkopf and J. Platt and T. Hoffman},
 pages = {},
 publisher = {MIT Press},
 title = {Analysis of Representations for Domain Adaptation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2006/file/b1b0432ceafb0ce714426e9114852ac7-Paper.pdf},
 volume = {19},
 year = {2006}
}

@article{gretton2012kernel,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={723--773},
  year={2012},
  publisher={JMLR. org}
}


@InProceedings{pmlr-v139-le21a,
  title = 	 {LAMDA: Label Matching Deep Domain Adaptation},
  author =       {Le, Trung and Nguyen, Tuan and Ho, Nhat and Bui, Hung and Phung, Dinh},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {6043--6054},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/le21a/le21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/le21a.html},
  abstract = 	 {Deep domain adaptation (DDA) approaches have recently been shown to perform better than their shallow rivals with better modeling capacity on complex domains (e.g., image, structural data, and sequential data). The underlying idea is to learn domain invariant representations on a latent space that can bridge the gap between source and target domains. Several theoretical studies have established insightful understanding and the benefit of learning domain invariant features; however, they are usually limited to the case where there is no label shift, hence hindering its applicability. In this paper, we propose and study a new challenging setting that allows us to use a Wasserstein distance (WS) to not only quantify the data shift but also to define the label shift directly. We further develop a theory to demonstrate that minimizing the WS of the data shift leads to closing the gap between the source and target data distributions on the latent space (e.g., an intermediate layer of a deep net), while still being able to quantify the label shift with respect to this latent space. Interestingly, our theory can consequently explain certain drawbacks of learning domain invariant features on the latent space. Finally, grounded on the results and guidance of our developed theory, we propose the Label Matching Deep Domain Adaptation (LAMDA) approach that outperforms baselines on real-world datasets for DA problems.}
}

@article{mansour2009domain,
  title={Domain adaptation: Learning bounds and algorithms},
  author={Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
  journal={arXiv preprint arXiv:0902.3430},
  year={2009}
}

@inproceedings{tan2021otce,
  title={Otce: A transferability metric for cross-domain cross-task representations},
  author={Tan, Yang and Li, Yang and Huang, Shao-Lun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={15779--15788},
  year={2021}
}

@article{bahng2022visual,
  title={Visual prompting: Modifying pixel space to adapt pre-trained models},
  author={Bahng, Hyojin and Jahanian, Ali and Sankaranarayanan, Swami and Isola, Phillip},
  journal={arXiv preprint arXiv:2203.17274},
  volume={2},
  number={3},
  pages={7},
  year={2022}
}

@inproceedings{wang2022learning,
  title={Learning to prompt for continual learning},
  author={Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={139--149},
  year={2022}
}

